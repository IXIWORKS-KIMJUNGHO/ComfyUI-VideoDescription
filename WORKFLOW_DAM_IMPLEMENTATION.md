# NVIDIA DAM-3B-Video ë…ë¦½ ë…¸ë“œ êµ¬í˜„ ì›Œí¬í”Œë¡œìš°

## ğŸ“‹ ì „ì²´ ê°œìš”

**ëª©í‘œ**: NVIDIA DAM-3B-Videoë¥¼ ì‚¬ìš©í•˜ëŠ” ë…ë¦½ì ì¸ ComfyUI ì»¤ìŠ¤í…€ ë…¸ë“œ êµ¬í˜„
**íŠ¹ì§•**: ë¹„ë””ì˜¤ì˜ íŠ¹ì • ì˜ì—­(region)ì— ëŒ€í•œ ìƒì„¸ ì„¤ëª… ìƒì„±
**ì˜ˆìƒ ì‘ì—… ì‹œê°„**: 4-6 ì‹œê°„

---

## ğŸ¯ Phase 1: í™˜ê²½ ì„¤ì • ë° ì˜ì¡´ì„± ì„¤ì¹˜ (30ë¶„)

### 1.1 DAM ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
```bash
# describe-anything íŒ¨í‚¤ì§€ ì„¤ì¹˜
cd /Volumes/KIMJUNGHO_SSD/ComfyUI
source .venv/bin/activate
pip install git+https://github.com/NVlabs/describe-anything

# ì˜ì¡´ì„± í™•ì¸
pip list | grep -E "torch|transformers|vila|sam"
```

**ê²€ì¦**:
- [ ] `describe-anything` íŒ¨í‚¤ì§€ ì„¤ì¹˜ í™•ì¸
- [ ] PyTorch, transformers ë²„ì „ í˜¸í™˜ì„± í™•ì¸
- [ ] VILA ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ í™•ì¸

### 1.2 ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë””ë ‰í† ë¦¬ ì¤€ë¹„
```bash
# DAM ëª¨ë¸ ì €ì¥ ê²½ë¡œ ìƒì„±
mkdir -p models/video_description/DAM-3B-Video

# ëª¨ë¸ í¬ê¸°: ì•½ 7.12GB
# ì˜ˆìƒ ë‹¤ìš´ë¡œë“œ ì‹œê°„: 5-15ë¶„ (ì¸í„°ë„· ì†ë„ì— ë”°ë¼)
```

**ê²€ì¦**:
- [ ] ë””ë ‰í† ë¦¬ ìƒì„± í™•ì¸
- [ ] ë””ìŠ¤í¬ ì—¬ìœ  ê³µê°„ 10GB ì´ìƒ í™•ì¸

---

## ğŸ”§ Phase 2: ëª¨ë¸ ë¡œë” êµ¬í˜„ (1-1.5ì‹œê°„)

### 2.1 DAM ëª¨ë¸ ìºì‹œ ë§¤ë‹ˆì € ìƒì„±

**íŒŒì¼**: `models/dam_cache.py`

```python
"""
DAM Model Cache Manager
Singleton pattern for DAM-3B-Video model management
"""

import torch
import logging
from pathlib import Path
from typing import Optional, Tuple

logger = logging.getLogger(__name__)


class DAMModelCache:
    """Singleton cache for DAM model"""

    _instance = None
    _model = None
    _processor = None

    @classmethod
    def get_instance(cls):
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance

    @classmethod
    def _get_model_path(cls) -> Path:
        """Get DAM model path in ComfyUI models directory"""
        # custom_nodes/ComfyUI-VideoDescription/models/dam_cache.py
        # â†’ ComfyUI/models/video_description/DAM-3B-Video/
        current_file = Path(__file__).resolve()
        custom_nodes_dir = current_file.parent.parent.parent
        comfyui_root = custom_nodes_dir.parent
        model_path = comfyui_root / "models" / "video_description" / "DAM-3B-Video"
        return model_path

    @classmethod
    def get_dam_model(cls, use_4bit: bool = False) -> Tuple:
        """
        Load and cache DAM-3B-Video model

        Args:
            use_4bit: Use 4-bit quantization (not supported yet for DAM)

        Returns:
            Tuple of (model, processor)
        """
        if cls._model is not None and cls._processor is not None:
            logger.info("Using cached DAM model")
            return cls._model, cls._processor

        logger.info("Loading DAM-3B-Video model for the first time...")
        model_path = cls._get_model_path()

        # Device detection
        if torch.cuda.is_available():
            device = "cuda"
            logger.info(f"Using CUDA device: {torch.cuda.get_device_name(0)}")
        elif torch.backends.mps.is_available():
            device = "mps"
            logger.info("Using MPS (Apple Silicon)")
        else:
            device = "cpu"
            logger.warning("No GPU detected, using CPU (will be slow)")

        # TODO: Implement actual DAM model loading
        # This will use the describe-anything library
        # from dam import DAMModel, DAMProcessor

        # For now, placeholder
        raise NotImplementedError("DAM model loading to be implemented")

        # cls._model = model
        # cls._processor = processor
        # return cls._model, cls._processor
```

**ì‘ì—… ë‚´ìš©**:
1. Singleton íŒ¨í„´ìœ¼ë¡œ ëª¨ë¸ ìºì‹±
2. ComfyUI í‘œì¤€ ë””ë ‰í† ë¦¬ êµ¬ì¡° ì‚¬ìš©
3. ë””ë°”ì´ìŠ¤ ìë™ ê°ì§€ (CUDA/MPS/CPU)
4. ì—ëŸ¬ í•¸ë“¤ë§ ë° ë¡œê¹…

**ê²€ì¦**:
- [ ] íŒŒì¼ ìƒì„± í™•ì¸
- [ ] import ì—ëŸ¬ ì—†ìŒ í™•ì¸
- [ ] ê²½ë¡œ í•´ì„ ë¡œì§ í…ŒìŠ¤íŠ¸

### 2.2 DAM ëª¨ë¸ ì‹¤ì œ ë¡œë”© ë¡œì§ ì—°êµ¬

**ë¦¬ì„œì¹˜ í•„ìš” ì‚¬í•­**:
```python
# describe-anything ë¼ì´ë¸ŒëŸ¬ë¦¬ API í™•ì¸
# 1. ëª¨ë¸ í´ë˜ìŠ¤ ì´ë¦„
# 2. í”„ë¡œì„¸ì„œ í´ë˜ìŠ¤ ì´ë¦„
# 3. ì´ˆê¸°í™” íŒŒë¼ë¯¸í„°
# 4. from_pretrained ì‚¬ìš©ë²•

# ì˜ˆìƒ ì½”ë“œ (í™•ì¸ í•„ìš”):
from dam import DAMModel, DAMProcessor  # ì‹¤ì œ import ê²½ë¡œ í™•ì¸ í•„ìš”

model = DAMModel.from_pretrained(
    "nvidia/DAM-3B-Video",
    cache_dir=str(model_path),
    device_map=device_map,
    torch_dtype=torch.float16
)

processor = DAMProcessor.from_pretrained(
    "nvidia/DAM-3B-Video",
    cache_dir=str(model_path)
)
```

**ê²€ì¦**:
- [ ] describe-anything ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¬¸ì„œ í™•ì¸
- [ ] ì‹¤ì œ API import í…ŒìŠ¤íŠ¸
- [ ] ëª¨ë¸ ë¡œë”© ì„±ê³µ í™•ì¸

---

## ğŸ¨ Phase 3: DAM Inference ë˜í¼ êµ¬í˜„ (1.5ì‹œê°„)

### 3.1 DAM Inference í´ë˜ìŠ¤ ìƒì„±

**íŒŒì¼**: `models/dam_inference.py`

```python
"""
DAM Inference Wrapper
Handles region-based video description with DAM-3B-Video
"""

import torch
import logging
from pathlib import Path
from typing import Union, List, Tuple, Optional

logger = logging.getLogger(__name__)


class DAMInference:
    """Wrapper for DAM-3B-Video inference"""

    def __init__(self, model, processor):
        self.model = model
        self.processor = processor
        self.device = model.device

    def generate_region_description(
        self,
        video_path: Union[str, Path],
        region_points: List[List[int]],
        prompt: str = "Describe what you see in the marked region.",
        max_new_tokens: int = 512,
        temperature: float = 0.2,
        top_p: float = 0.9,
        num_beams: int = 1
    ) -> str:
        """
        Generate description for specified region in video

        Args:
            video_path: Path to video file
            region_points: List of [x, y] coordinates marking region
                          e.g., [[100, 200]] for single point
                          e.g., [[100, 200], [300, 400]] for box
            prompt: Text prompt for description
            max_new_tokens: Maximum tokens to generate
            temperature: Sampling temperature
            top_p: Top-p sampling
            num_beams: Number of beams for beam search

        Returns:
            Generated region description
        """
        logger.info(f"Generating region description for: {Path(video_path).name}")
        logger.info(f"Region points: {region_points}")

        try:
            # TODO: Implement actual DAM inference
            # Expected workflow:
            # 1. Load video
            # 2. Process region coordinates
            # 3. Apply focal prompt with region
            # 4. Generate description

            raise NotImplementedError("DAM inference to be implemented")

        except Exception as e:
            logger.error(f"Error during DAM inference: {e}")
            raise

    def generate_multi_region_description(
        self,
        video_path: Union[str, Path],
        regions: List[List[List[int]]],
        prompts: Optional[List[str]] = None,
        **kwargs
    ) -> List[str]:
        """
        Generate descriptions for multiple regions

        Args:
            video_path: Path to video file
            regions: List of region point lists
            prompts: Optional list of prompts (one per region)
            **kwargs: Additional generation parameters

        Returns:
            List of descriptions (one per region)
        """
        if prompts is None:
            prompts = ["Describe what you see in this region."] * len(regions)

        descriptions = []
        for region, prompt in zip(regions, prompts):
            desc = self.generate_region_description(
                video_path=video_path,
                region_points=region,
                prompt=prompt,
                **kwargs
            )
            descriptions.append(desc)

        return descriptions
```

**ì‘ì—… ë‚´ìš©**:
1. ë‹¨ì¼ ì˜ì—­ ì„¤ëª… ìƒì„±
2. ë‹¤ì¤‘ ì˜ì—­ ì„¤ëª… ìƒì„± (ë°°ì¹˜)
3. ë‹¤ì–‘í•œ ìƒì„± íŒŒë¼ë¯¸í„° ì§€ì›
4. ì—ëŸ¬ í•¸ë“¤ë§

**ê²€ì¦**:
- [ ] íŒŒì¼ ìƒì„± í™•ì¸
- [ ] í´ë˜ìŠ¤ êµ¬ì¡° ê²€í† 
- [ ] íŒŒë¼ë¯¸í„° íƒ€ì… íŒíŒ… í™•ì¸

### 3.2 Region ì…ë ¥ í˜•ì‹ ì„¤ê³„

**ì§€ì›í•  Region í˜•ì‹**:
```python
# 1. Single Point (ê´€ì‹¬ ì§€ì )
region_points = [[x, y]]
# ì˜ˆ: [[100, 200]]

# 2. Bounding Box (ì‚¬ê°í˜• ì˜ì—­)
region_points = [[x1, y1], [x2, y2]]
# ì˜ˆ: [[100, 200], [300, 400]]

# 3. Multiple Points (í´ë¦¬ê³¤)
region_points = [[x1, y1], [x2, y2], [x3, y3], ...]
# ì˜ˆ: [[100, 200], [200, 250], [150, 300]]
```

**ComfyUI ì…ë ¥ ì²˜ë¦¬**:
```python
# STRING íƒ€ì…ìœ¼ë¡œ JSON ì…ë ¥ ë°›ê¸°
region_input = "[[100, 200]]"  # ì‚¬ìš©ì ì…ë ¥

# íŒŒì‹±
import json
region_points = json.loads(region_input)

# ê²€ì¦
if not isinstance(region_points, list):
    raise ValueError("Region points must be a list")
```

**ê²€ì¦**:
- [ ] JSON íŒŒì‹± ë¡œì§ í…ŒìŠ¤íŠ¸
- [ ] ë‹¤ì–‘í•œ í˜•ì‹ ì…ë ¥ ê²€ì¦
- [ ] ì—ëŸ¬ ë©”ì‹œì§€ ëª…í™•ì„± í™•ì¸

---

## ğŸ­ Phase 4: ComfyUI ë…¸ë“œ êµ¬í˜„ (2ì‹œê°„)

### 4.1 DAM ë¹„ë””ì˜¤ ì„¤ëª… ë…¸ë“œ ìƒì„±

**íŒŒì¼**: `video_nodes.py` (ê¸°ì¡´ íŒŒì¼ì— ì¶”ê°€)

```python
class VideoDescriptionDAM:
    """
    Video description node using NVIDIA DAM-3B-Video
    Generates detailed descriptions of specific regions in video
    """

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "video_path": ("STRING", {
                    "default": "",
                    "multiline": False
                }),
                "region_points": ("STRING", {
                    "default": "[[100, 100]]",
                    "multiline": False,
                    "tooltip": "JSON format: [[x,y]] or [[x1,y1],[x2,y2]]"
                }),
                "analysis_type": (["detailed", "summary", "action"], {
                    "default": "detailed"
                }),
            },
            "optional": {
                "custom_prompt": ("STRING", {
                    "default": "",
                    "multiline": True
                }),
                "use_4bit": ("BOOLEAN", {
                    "default": False
                }),
                "temperature": ("FLOAT", {
                    "default": 0.2,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.1
                }),
            }
        }

    RETURN_TYPES = ("STRING", "STRING")
    RETURN_NAMES = ("description", "info")
    FUNCTION = "describe_region"
    CATEGORY = "video"

    @classmethod
    def _get_analysis_prompt(cls, analysis_type: str, custom_prompt: str = "") -> Tuple[str, int, float]:
        """Get optimized prompt for DAM analysis"""
        if custom_prompt and custom_prompt.strip():
            return (custom_prompt.strip(), 512, 0.2)

        analysis_configs = {
            "detailed": {
                "prompt": (
                    "Provide a comprehensive and detailed description of the marked region. "
                    "Include information about:\n"
                    "- Objects and subjects in the region\n"
                    "- Actions and movements\n"
                    "- Visual characteristics (colors, textures, lighting)\n"
                    "- Interactions with surroundings\n"
                    "- Temporal changes throughout the video"
                ),
                "max_tokens": 512,
                "temperature": 0.2
            },
            "summary": {
                "prompt": (
                    "Provide a brief summary of what happens in the marked region "
                    "in 2-3 sentences."
                ),
                "max_tokens": 256,
                "temperature": 0.2
            },
            "action": {
                "prompt": (
                    "Describe the specific actions and movements occurring in "
                    "the marked region."
                ),
                "max_tokens": 384,
                "temperature": 0.2
            }
        }

        config = analysis_configs.get(analysis_type, analysis_configs["detailed"])
        return (config["prompt"], config["max_tokens"], config["temperature"])

    def describe_region(self, video_path, region_points, analysis_type,
                       custom_prompt="", use_4bit=False, temperature=0.2):
        """
        Generate region-based video description using DAM

        Args:
            video_path: Path to video file
            region_points: JSON string of region coordinates
            analysis_type: Type of analysis (detailed/summary/action)
            custom_prompt: Optional custom prompt
            use_4bit: Use 4-bit quantization
            temperature: Sampling temperature

        Returns:
            Tuple of (description, info)
        """
        try:
            # Resolve video path
            video_path = video_path.strip()
            if not video_path:
                return ("Error: Video path is empty", "Please provide a video path")

            resolved_path = VideoDescriptionQwen3VL._resolve_video_path(video_path)

            # Parse region points
            import json
            try:
                points = json.loads(region_points)
                if not isinstance(points, list) or len(points) == 0:
                    return ("Error: Invalid region format", "Region must be non-empty list")
            except json.JSONDecodeError as e:
                return (f"Error: Invalid JSON format: {str(e)}", "Check region_points syntax")

            # Get analysis configuration
            prompt, max_tokens, config_temp = self._get_analysis_prompt(analysis_type, custom_prompt)
            if not custom_prompt:
                temperature = config_temp

            # Get video info
            from processing.video_processor import VideoProcessor
            video_info = VideoProcessor.get_video_info(resolved_path)
            video_source = Path(resolved_path).name

            info_text = (
                f"Source: {video_source}\n"
                f"Type: DAM Region Analysis ({analysis_type})\n"
                f"Region: {region_points}\n"
                f"Duration: {video_info['duration']:.2f}s\n"
                f"Resolution: {video_info['width']}x{video_info['height']}\n"
                f"Max tokens: {max_tokens}\n"
                f"Temperature: {temperature:.2f}\n"
                f"4-bit: {use_4bit}"
            )

            logger.info(f"Processing region-based video: {video_source}")
            logger.info(f"Analysis type: {analysis_type}")
            logger.info(f"Region points: {points}")

            # Load DAM model
            logger.info("Loading DAM-3B-Video model...")
            from models.dam_cache import DAMModelCache
            model, processor = DAMModelCache.get_dam_model(use_4bit=use_4bit)

            # Create inference wrapper
            from models.dam_inference import DAMInference
            inference = DAMInference(model, processor)

            # Generate description
            description = inference.generate_region_description(
                video_path=resolved_path,
                region_points=points,
                prompt=prompt,
                max_new_tokens=max_tokens,
                temperature=temperature
            )

            return (description, info_text)

        except Exception as e:
            error_msg = f"Error during DAM inference: {str(e)}"
            logger.error(error_msg)
            return (f"Error: {error_msg}", f"Exception: {type(e).__name__}")


# Add to NODE_CLASS_MAPPINGS
NODE_CLASS_MAPPINGS = {
    "VideoDescriptionQwen3VL": VideoDescriptionQwen3VL,
    "VideoDescriptionDAM": VideoDescriptionDAM,  # â† ì¶”ê°€
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "VideoDescriptionQwen3VL": "Video Description (Qwen3-VL)",
    "VideoDescriptionDAM": "Video Description (DAM Region)",  # â† ì¶”ê°€
}
```

**ì‘ì—… ë‚´ìš©**:
1. ë…ë¦½ì ì¸ DAM ë…¸ë“œ í´ë˜ìŠ¤
2. Region ê¸°ë°˜ ì…ë ¥ ì²˜ë¦¬
3. 3ê°€ì§€ ë¶„ì„ íƒ€ì… í”„ë¦¬ì…‹
4. Qwen3-VL ë…¸ë“œì™€ ìœ ì‚¬í•œ êµ¬ì¡°

**ê²€ì¦**:
- [ ] INPUT_TYPES êµ¬ì¡° í™•ì¸
- [ ] Region íŒŒì‹± ë¡œì§ í…ŒìŠ¤íŠ¸
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ê²€ì¦

---

## ğŸ§ª Phase 5: í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ (1-1.5ì‹œê°„)

### 5.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±

**íŒŒì¼**: `test_dam.py`

```python
"""
Test DAM model integration
"""
import sys
import json
from pathlib import Path

current_dir = Path(__file__).parent
sys.path.insert(0, str(current_dir))

def test_dam_region_description():
    """Test DAM region-based video description"""

    print("=" * 70)
    print("DAM Region Description Test")
    print("=" * 70)
    print()

    # Test video
    video_path = current_dir / "test.mp4"
    if not video_path.exists():
        print(f"âš ï¸ Test video not found: {video_path}")
        print("Please copy a test video to this directory")
        return

    # Test regions
    test_regions = [
        ([[100, 100]], "Single point - center focus"),
        ([[50, 50], [200, 200]], "Bounding box - top-left region"),
        ([[800, 500]], "Single point - right side"),
    ]

    print(f"Test video: {video_path}")
    print(f"Video size: {video_path.stat().st_size / 1024:.1f} KB")
    print()

    # Load model
    print("Loading DAM model...")
    try:
        from models.dam_cache import DAMModelCache
        from models.dam_inference import DAMInference

        model, processor = DAMModelCache.get_dam_model()
        inference = DAMInference(model, processor)
        print("âœ“ Model loaded successfully")
        print()
    except Exception as e:
        print(f"âœ— Model loading failed: {e}")
        return

    # Test each region
    for region_points, description in test_regions:
        print("-" * 70)
        print(f"Test: {description}")
        print(f"Region: {region_points}")
        print()

        try:
            result = inference.generate_region_description(
                video_path=str(video_path),
                region_points=region_points,
                prompt="Describe what you see in the marked region.",
                max_new_tokens=256
            )

            print("Result:")
            print(result)
            print()
            print("âœ“ Test passed")

        except Exception as e:
            print(f"âœ— Test failed: {e}")

        print()

    print("=" * 70)
    print("Test completed")
    print("=" * 70)

if __name__ == "__main__":
    test_dam_region_description()
```

**í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**:
1. ë‹¨ì¼ í¬ì¸íŠ¸ region
2. ë°”ìš´ë”© ë°•ìŠ¤ region
3. ë‹¤ì–‘í•œ ìœ„ì¹˜ í…ŒìŠ¤íŠ¸

**ê²€ì¦**:
- [ ] ëª¨ë¸ ë¡œë”© ì„±ê³µ
- [ ] Region íŒŒì‹± ì •ìƒ ì‘ë™
- [ ] ì„¤ëª… ìƒì„± ì„±ê³µ
- [ ] ê° region íƒ€ì…ë³„ í…ŒìŠ¤íŠ¸ í†µê³¼

### 5.2 ComfyUI í†µí•© í…ŒìŠ¤íŠ¸

**í…ŒìŠ¤íŠ¸ ì ˆì°¨**:
```bash
# 1. ComfyUI ì¬ì‹œì‘
cd /Volumes/KIMJUNGHO_SSD/ComfyUI
source .venv/bin/activate
python main.py

# 2. ë¸Œë¼ìš°ì €ì—ì„œ í™•ì¸
# - ë…¸ë“œ ë©”ë‰´ì—ì„œ "video" ì¹´í…Œê³ ë¦¬ í™•ì¸
# - "Video Description (DAM Region)" ë…¸ë“œ ì¡´ì¬ í™•ì¸

# 3. ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸
# - video_path: test.mp4
# - region_points: [[100, 100]]
# - analysis_type: detailed
# - ì‹¤í–‰ ë° ê²°ê³¼ í™•ì¸
```

**ê²€ì¦**:
- [ ] ë…¸ë“œê°€ UIì— ë‚˜íƒ€ë‚¨
- [ ] íŒŒë¼ë¯¸í„° ì…ë ¥ ì •ìƒ
- [ ] ì‹¤í–‰ ì‹œ ì—ëŸ¬ ì—†ìŒ
- [ ] ê²°ê³¼ ì¶œë ¥ í™•ì¸

---

## ğŸ“š Phase 6: ë¬¸ì„œí™” (30ë¶„)

### 6.1 USAGE.md ì—…ë°ì´íŠ¸

**ì¶”ê°€ ì„¹ì…˜**:
```markdown
## ğŸ¯ DAM Region-Based Analysis

### Video Description (DAM Region) Node

NVIDIA DAM-3B-Video ëª¨ë¸ì„ ì‚¬ìš©í•œ ì§€ì—­ ê¸°ë°˜ ë¹„ë””ì˜¤ ë¶„ì„

#### Required Parameters
- `video_path`: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
- `region_points`: ê´€ì‹¬ ì˜ì—­ ì¢Œí‘œ (JSON í˜•ì‹)
  - Single point: `[[x, y]]`
  - Bounding box: `[[x1, y1], [x2, y2]]`
  - Polygon: `[[x1, y1], [x2, y2], [x3, y3], ...]`
- `analysis_type`: ë¶„ì„ íƒ€ì…
  - `detailed`: ìƒì„¸ ì„¤ëª…
  - `summary`: ê°„ë‹¨ ìš”ì•½
  - `action`: í–‰ë™ ë¶„ì„

#### Region ì¢Œí‘œ ì…ë ¥ ê°€ì´ë“œ
...
```

### 6.2 README.md ì—…ë°ì´íŠ¸

**Current Nodes ì„¹ì…˜ì— ì¶”ê°€**:
```markdown
### Video Description (DAM Region) - v1.0.0

**Status**: Experimental - Region-based video analysis

**Description**: Uses NVIDIA DAM-3B-Video for detailed descriptions
of user-specified regions within videos.

**Key Features**:
- Region-based analysis (points, boxes, polygons)
- High-detail localized descriptions
- Action-focused analysis option
...
```

---

## âœ… ìµœì¢… ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì½”ë“œ í’ˆì§ˆ
- [ ] ëª¨ë“  íŒŒì¼ì— docstring ì‘ì„±
- [ ] Type hints ì ìš©
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ ì™„ë¹„
- [ ] ë¡œê¹… ë©”ì‹œì§€ ì ì ˆ

### ê¸°ëŠ¥ ê²€ì¦
- [ ] DAM ëª¨ë¸ ë¡œë”© ì„±ê³µ
- [ ] Region íŒŒì‹± ì •ìƒ ì‘ë™
- [ ] 3ê°€ì§€ ë¶„ì„ íƒ€ì… ëª¨ë‘ ì‘ë™
- [ ] ComfyUIì—ì„œ ë…¸ë“œ ì‹¤í–‰ ì„±ê³µ

### ì„±ëŠ¥ ê²€ì¦
- [ ] ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸ (DAM 7GB)
- [ ] ì¶”ë¡  ì†ë„ ì¸¡ì • (ë²¤ì¹˜ë§ˆí¬)
- [ ] GPU í™œìš©ë¥  í™•ì¸

### ë¬¸ì„œí™”
- [ ] USAGE.md ì—…ë°ì´íŠ¸ ì™„ë£Œ
- [ ] README.md ì—…ë°ì´íŠ¸ ì™„ë£Œ
- [ ] ì˜ˆì œ ì½”ë“œ í¬í•¨
- [ ] íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ê°€ì´ë“œ ì‘ì„±

---

## ğŸš€ êµ¬í˜„ ìˆœì„œ ìš”ì•½

1. **í™˜ê²½ ì„¤ì •** (30ë¶„)
   - pip install describe-anything
   - ë””ë ‰í† ë¦¬ ì¤€ë¹„

2. **ëª¨ë¸ ë¡œë”** (1-1.5ì‹œê°„)
   - dam_cache.py ì‘ì„±
   - ì‹¤ì œ API ì—°êµ¬ ë° êµ¬í˜„

3. **Inference ë˜í¼** (1.5ì‹œê°„)
   - dam_inference.py ì‘ì„±
   - Region ì²˜ë¦¬ ë¡œì§ êµ¬í˜„

4. **ComfyUI ë…¸ë“œ** (2ì‹œê°„)
   - VideoDescriptionDAM í´ë˜ìŠ¤ ì‘ì„±
   - INPUT_TYPES ì •ì˜
   - ë…¸ë“œ ë“±ë¡

5. **í…ŒìŠ¤íŠ¸** (1-1.5ì‹œê°„)
   - ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„± ë° ì‹¤í–‰
   - ComfyUI í†µí•© í…ŒìŠ¤íŠ¸

6. **ë¬¸ì„œí™”** (30ë¶„)
   - USAGE.md, README.md ì—…ë°ì´íŠ¸

**ì´ ì˜ˆìƒ ì‹œê°„**: 6-8ì‹œê°„

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **ë¼ì´ì„ ìŠ¤**: NVIDIA DAMì€ ë¹„ìƒì—…ì  ì—°êµ¬ ë¼ì´ì„ ìŠ¤
2. **ë©”ëª¨ë¦¬**: DAM(7GB) + Qwen3-VL(16GB) ë™ì‹œ ì‚¬ìš© ì‹œ 23GB VRAM í•„ìš”
3. **Region ì¢Œí‘œ**: ë¹„ë””ì˜¤ í•´ìƒë„ì— ë§ëŠ” ì ˆëŒ€ ì¢Œí‘œ ì‚¬ìš©
4. **describe-anything API**: ê³µì‹ ë¬¸ì„œê°€ ì œí•œì ì´ë¯€ë¡œ ì½”ë“œ ì§ì ‘ í™•ì¸ í•„ìš”

---

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ

êµ¬í˜„ ì™„ë£Œ í›„:
1. **ë“€ì–¼ ëª¨ë¸ ë…¸ë“œ** ê°œë°œ (Qwen3-VL + DAM ì¡°í•©)
2. **SAM2 í†µí•©** (ìë™ region ê°ì§€)
3. **ë°°ì¹˜ ì²˜ë¦¬** ì§€ì›
4. **ì‹œê°„ ê¸°ë°˜ region** ì§€ì› (íŠ¹ì • í”„ë ˆì„ ë²”ìœ„)
